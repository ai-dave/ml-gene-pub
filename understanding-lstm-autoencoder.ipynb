{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning LSTM Autoencoder and LSTM Network on a simple Multivariate Timeseries Toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm autoencoder to recreate a timeseries\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A UDF to convert input data into 3-D\n",
    "array as required for LSTM network.\n",
    "'''\n",
    "\n",
    "def temporalize(X, y, lookback):\n",
    "    output_X = []\n",
    "    output_y = []\n",
    "    for i in range(len(X)-lookback-1):\n",
    "        t = []\n",
    "        for j in range(1,lookback+1):\n",
    "            # Gather past records upto the lookback period\n",
    "            t.append(X[[(i+j+1)], :])\n",
    "        output_X.append(t)\n",
    "        output_y.append(y[i+lookback+1])\n",
    "    return output_X, output_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1  , 0.001],\n",
       "       [0.2  , 0.008],\n",
       "       [0.3  , 0.027],\n",
       "       [0.4  , 0.064],\n",
       "       [0.5  , 0.125],\n",
       "       [0.6  , 0.216],\n",
       "       [0.7  , 0.343],\n",
       "       [0.8  , 0.512],\n",
       "       [0.9  , 0.729]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define input timeseries\n",
    "timeseries = np.array([[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "                       [0.1**3, 0.2**3, 0.3**3, 0.4**3, 0.5**3, 0.6**3, 0.7**3, 0.8**3, 0.9**3]]).transpose()\n",
    "\n",
    "timesteps = timeseries.shape[0]\n",
    "n_features = timeseries.shape[1]\n",
    "timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.3  , 0.027],\n",
       "        [0.4  , 0.064],\n",
       "        [0.5  , 0.125]],\n",
       "\n",
       "       [[0.4  , 0.064],\n",
       "        [0.5  , 0.125],\n",
       "        [0.6  , 0.216]],\n",
       "\n",
       "       [[0.5  , 0.125],\n",
       "        [0.6  , 0.216],\n",
       "        [0.7  , 0.343]],\n",
       "\n",
       "       [[0.6  , 0.216],\n",
       "        [0.7  , 0.343],\n",
       "        [0.8  , 0.512]],\n",
       "\n",
       "       [[0.7  , 0.343],\n",
       "        [0.8  , 0.512],\n",
       "        [0.9  , 0.729]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timesteps = 3\n",
    "X, y = temporalize(X = timeseries, y = np.zeros(len(timeseries)), lookback = timesteps)\n",
    "\n",
    "n_features = 2\n",
    "X = np.array(X)\n",
    "X = X.reshape(X.shape[0], timesteps, n_features)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-10 16:18:46.731870: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 3, 128)            67072     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 3, 64)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 3, 64)             33024     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 3, 128)            98816     \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 3, 2)             258       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 248,578\n",
      "Trainable params: 248,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, activation='relu', input_shape=(timesteps,n_features), return_sequences=True))\n",
    "model.add(LSTM(64, activation='relu', return_sequences=False))\n",
    "model.add(RepeatVector(timesteps))\n",
    "model.add(LSTM(64, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_features)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Predicted---\n",
      "[[[0.32  0.035]\n",
      "  [0.408 0.064]\n",
      "  [0.494 0.121]]\n",
      "\n",
      " [[0.389 0.066]\n",
      "  [0.498 0.128]\n",
      "  [0.595 0.215]]\n",
      "\n",
      " [[0.493 0.119]\n",
      "  [0.602 0.219]\n",
      "  [0.703 0.344]]\n",
      "\n",
      " [[0.595 0.204]\n",
      "  [0.701 0.343]\n",
      "  [0.804 0.513]]\n",
      "\n",
      " [[0.704 0.349]\n",
      "  [0.799 0.51 ]\n",
      "  [0.898 0.729]]]\n",
      "---Actual---\n",
      "[[[0.3   0.027]\n",
      "  [0.4   0.064]\n",
      "  [0.5   0.125]]\n",
      "\n",
      " [[0.4   0.064]\n",
      "  [0.5   0.125]\n",
      "  [0.6   0.216]]\n",
      "\n",
      " [[0.5   0.125]\n",
      "  [0.6   0.216]\n",
      "  [0.7   0.343]]\n",
      "\n",
      " [[0.6   0.216]\n",
      "  [0.7   0.343]\n",
      "  [0.8   0.512]]\n",
      "\n",
      " [[0.7   0.343]\n",
      "  [0.8   0.512]\n",
      "  [0.9   0.729]]]\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X, X, epochs=300, batch_size=5, verbose=0)\n",
    "# demonstrate reconstruction\n",
    "yhat = model.predict(X, verbose=0)\n",
    "print('---Predicted---')\n",
    "print(np.round(yhat,3))\n",
    "print('---Actual---')\n",
    "print(np.round(X, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 3, 128)            67072     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 3, 64)             49408     \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 3, 64)             33024     \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 3, 128)            98816     \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 3, 2)             258       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 248,578\n",
      "Trainable params: 248,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, activation='relu', input_shape=(timesteps,n_features), return_sequences=True))\n",
    "model.add(LSTM(64, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(64, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(128, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_features)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Predicted---\n",
      "[[[0.339 0.063]\n",
      "  [0.4   0.045]\n",
      "  [0.504 0.121]]\n",
      "\n",
      " [[0.398 0.092]\n",
      "  [0.501 0.12 ]\n",
      "  [0.605 0.223]]\n",
      "\n",
      " [[0.474 0.142]\n",
      "  [0.603 0.219]\n",
      "  [0.697 0.351]]\n",
      "\n",
      " [[0.581 0.215]\n",
      "  [0.701 0.345]\n",
      "  [0.796 0.519]]\n",
      "\n",
      " [[0.718 0.312]\n",
      "  [0.802 0.519]\n",
      "  [0.908 0.735]]]\n",
      "---Actual---\n",
      "[[[0.3   0.027]\n",
      "  [0.4   0.064]\n",
      "  [0.5   0.125]]\n",
      "\n",
      " [[0.4   0.064]\n",
      "  [0.5   0.125]\n",
      "  [0.6   0.216]]\n",
      "\n",
      " [[0.5   0.125]\n",
      "  [0.6   0.216]\n",
      "  [0.7   0.343]]\n",
      "\n",
      " [[0.6   0.216]\n",
      "  [0.7   0.343]\n",
      "  [0.8   0.512]]\n",
      "\n",
      " [[0.7   0.343]\n",
      "  [0.8   0.512]\n",
      "  [0.9   0.729]]]\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X, X, epochs=300, batch_size=5, verbose=0)\n",
    "# demonstrate reconstruction\n",
    "yhat = model.predict(X, verbose=0)\n",
    "print('---Predicted---')\n",
    "print(np.round(yhat,3))\n",
    "print('---Actual---')\n",
    "print(np.round(X, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
